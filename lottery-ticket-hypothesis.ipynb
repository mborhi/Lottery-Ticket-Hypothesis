{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor \n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True, \n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a feed forward network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class fc1(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(fc1, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(28*28, 300),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weights\n",
    "import torch.nn.init as init\n",
    "\n",
    "def init_weights(module) :\n",
    "    if isinstance(module, nn.Linear) :\n",
    "        init.xavier_normal_(module.weight.data)\n",
    "        init.normal_(module.bias.data)\n",
    "    else :\n",
    "        ValueError\n",
    "\n",
    "# init feed forward\n",
    "model = fc1()\n",
    "model.apply(init_weights)\n",
    "# saved config\n",
    "initial_dict = copy.deepcopy(model.state_dict())\n",
    "# add optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=1e-4) \n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "# def loss fn\n",
    "loss_func = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Masking and Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define masking function\n",
    "def make_mask(model) :\n",
    "    \"\"\"Initializes a mask for the given model. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: extends(nn.Module)\n",
    "        The model to create the mask for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list[Tensor]\n",
    "        The mask.\n",
    "    \"\"\"\n",
    "    mask = [None] * sum(1 for name, param in model.named_parameters() if \"weight\" in name)\n",
    "    print(mask)\n",
    "    layer = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name :\n",
    "            tensor = param.data\n",
    "            mask[layer] = torch.ones_like(tensor)\n",
    "            layer += 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "mask = make_mask(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_percentile(percent: float, mask: list[torch.Tensor]) -> list[torch.Tensor] :\n",
    "    \"\"\"Prunes mask based on percentile.\n",
    "\n",
    "    Iterates over the given mask, settings all weights to zero in each tensor's layer\n",
    "    if it is under the given percentile value.\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    percent: float\n",
    "        Value from 0 to 1\n",
    "    mask: list[torch.Tensor]\n",
    "        List of tensors that make up the mask\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    list[torch.Tensor]\n",
    "        List of tensors that make up the pruned mask\n",
    "    \"\"\"\n",
    "    layer = 0\n",
    "    for name, param in model.named_parameters() :\n",
    "        if 'weight' in name:\n",
    "            tensor = param.data\n",
    "            torch_nonzero = torch.nonzero(tensor, as_tuple=True)\n",
    "            alive = tensor[torch_nonzero]\n",
    "            percentile_value = torch.quantile(abs(alive), percent).item()\n",
    "            new_mask = torch.from_numpy(np.where(abs(tensor) < percentile_value, 0, mask[layer]))\n",
    "            mask[layer] = new_mask\n",
    "            layer += 1\n",
    "    return mask\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_nodes(model) :\n",
    "    total = 0\n",
    "    for name, param in model.named_parameters() :\n",
    "        if \"weight\" in name :\n",
    "            total += torch.count_nonzero(param.data)\n",
    "    return total\n",
    "original_nodes = total_nodes(model)\n",
    "print(\"Total nodes:\", original_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for pruning, masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resets the mask\n",
    "def reset_mask(mask):\n",
    "    \"\"\"Resets the given mask.\n",
    "        \n",
    "    Sets the given mask to have all ones.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask: list[Tensor]\n",
    "        The mask to reset\n",
    "    \"\"\"\n",
    "    for step in range(len(mask)) :\n",
    "        new_mask = torch.ones_like(mask[step])\n",
    "        mask[step] = new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset to original\n",
    "def reset_to_original_init(model, mask, initial_dict) :\n",
    "    \"\"\"Resets the given model to the originally intialized paramaters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: extends(nn.Module)\n",
    "        The model to reset\n",
    "    mask: list[torch.Tensor]\n",
    "        The mask to reset\n",
    "    initial_dict: Dict[str, Any]\n",
    "        Dictionary values containing values to reset to\n",
    "    \"\"\"\n",
    "    layer = 0\n",
    "    for name, param in model.named_parameters() :\n",
    "        if \"weight\" in name :\n",
    "            param.data = initial_dict[name] * mask[layer]\n",
    "            layer += 1\n",
    "        if \"bias\" in name :\n",
    "            param.data = initial_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full reset to init\n",
    "def full_reset(model, mask, initial_dict) :\n",
    "    \"\"\"Fully resets the given model and mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        The model to reset\n",
    "    mask: list[torch.Tensor]\n",
    "        The mask to reset\n",
    "    initial_dict: Dict[str, Any]\n",
    "        Dictionary values containing values to reset to\n",
    "    \"\"\"    \n",
    "    reset_mask(mask)\n",
    "    reset_to_original_init(model, mask, initial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_reset(model, mask, initial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train_prune(model, loaders, loss_func):\n",
    "    \"\"\"Trains the given model with pruning.\n",
    "    \n",
    "    Trains the given model on the given training set using the given loss function. Ignores the values of\n",
    "    pruned weights by assigning zero to their gradients.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: extends(nn.Module)\n",
    "        The model to train with pruning.\n",
    "    loaders: Dict[str, DataLoader]\n",
    "        The dictionary containing the training data set.\n",
    "    loss_func: LossFunction\n",
    "        The loss function to use.\n",
    "    \"\"\"\n",
    "\n",
    "    EPS = 1e-6\n",
    "    size = len(loaders[\"train\"].dataset)\n",
    "    for batch_idx, (imgs, targets) in enumerate(loaders['train']) :\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(imgs)\n",
    "        train_loss = loss_func(pred, targets)\n",
    "        train_loss.backward()\n",
    "\n",
    "        for name, param in model.named_parameters() :\n",
    "            if \"weight\" in name:\n",
    "                # tensor = param.data.cpu().numpy()\n",
    "                tensor = param.data\n",
    "                # grad_tensor = param.grad.data.cpu().numpy()\n",
    "                grad_tensor = param.grad.data\n",
    "                # assign 0 to gradient of pruned weight\n",
    "                # grad_tensor = np.where(tensor < EPS, 0, grad_tensor)\n",
    "                grad_tensor = torch.where(tensor < EPS, 0, grad_tensor)\n",
    "                # param.grad.data = torch.from_numpy(grad_tensor)\n",
    "                param.grad.data = grad_tensor\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = train_loss.item(), batch_idx * len(imgs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loaders, loss_func) :\n",
    "    \"\"\"Tests the given model. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: extends(nn.Module)\n",
    "        The model to train with pruning.\n",
    "    loaders: Dict[str, DataLoader]\n",
    "        The dictionary containing the training data set.\n",
    "    loss_func: LossFunction\n",
    "        The loss function to use.\n",
    "    \"\"\"\n",
    "    test_dataloader = loaders[\"test\"]\n",
    "    size = len(test_dataloader.dataset) \n",
    "    num_batches = len(test_dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for X, y in test_dataloader :\n",
    "            pred = model(X)\n",
    "            test_loss += loss_func(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, loaders, loss_func)\n",
    "nodes = total_nodes(model)\n",
    "# print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Number of nodes: {nodes}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Pruning with Resetting\n",
    "\n",
    "1. Randomly initialize a neural network f(x; m \f θ) where θ = θ0 and m = 1|θ|\n",
    "is a mask.\n",
    "2. Train the network for j iterations, reaching parameters m \f θj .\n",
    "3. Prune s% of the parameters, creating an updated mask m0 where Pm0 = (Pm − s)%.\n",
    "4. Reset the weights of the remaining portion of the network to their values in θ0. That is, let\n",
    "θ = θ0.\n",
    "5. Let m = m0\n",
    "and repeat steps 2 through 4 until a sufficiently pruned network has been\n",
    "obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "prune_percent = 0.5\n",
    "iterations = 6\n",
    "\n",
    "def iterative_prune_train(model, mask, loss_func, iterations, percent) :\n",
    "    for epoch in range(epochs) :\n",
    "        print(\"epoch:\", epoch)\n",
    "        ### Train\n",
    "        model.train()\n",
    "        for t in range(iterations) :\n",
    "            print(f\"Iteration {t+1}\\n-------------------------------\")\n",
    "            train_prune(model, loaders, loss_func)\n",
    "            test(model, loaders, loss_func)\n",
    "        ### Prune\n",
    "        mask = prune_percentile(percent, mask)\n",
    "        ### Reset\n",
    "        reset_to_original_init(model, mask, initial_dict) \n",
    "        print(f\"\\n--- Pruning Level [{epoch}/{epochs}]: ---\")\n",
    "\n",
    "iterative_prune_train(model, mask, loss_func, iterations, prune_percent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test\n",
    "Train and test the fully pruned model, and evaluate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model.train()\n",
    "for t in range(epochs) :\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_prune(model, loaders, loss_func)\n",
    "    test(model, loaders, loss_func)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func = nn.CrossEntropyLoss()\n",
    "# full_reset(model, mask, initial_dict)\n",
    "test(model, loaders, loss_func)\n",
    "nodes = total_nodes(model)\n",
    "# print(f\"Accuracy: {acc:.3f}\")\n",
    "print(f\"Number of nodes: {nodes}\")\n",
    "print(f\"Percent of nodes left: {(nodes / original_nodes):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Training, Testing\n",
    "\n",
    "Fully reset the model along with the mask, and train normally without any pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_reset(model, mask, initial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model.train()\n",
    "for t in range(epochs) :\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(loaders[\"train\"], model, loss_func, optimizer)\n",
    "    test(model, loaders, loss_func)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lottery-ticket-hypothesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1aa0684e6170e93fae20cb7bbc4cc72120137157b335f9f696423b17a079d30a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
